<article id="projects" style="display:none;">

<h2>Projects under construction</h2>

<p>In the past years I have worked on a number of projects but published little. Here is an overview of some of the projects:</p>

<h3>Information theory&nbsp;</h3>

<ul>
  <li>A General theory of Information and Computation</strong>.&nbsp;</span></span><span>In the coming years I will write down a final summary of some of the research projects I have been working on for the past 45 years. The a preliminary version of the first report on the interaction between Information and Computation has been published this week on&nbsp;</span><a title="A General Theory of Information and Computation" href="https://arxiv.org/abs/1611.07829">arXiv</a><span>. It offers a new perspective on information theor by treating it as a purely mathematical subject. &nbsp;I'll be teaching a class on part of the material at the&nbsp;</span><a title="ILLC" href="https://www.illc.uva.nl/">ILLC</a><span>&nbsp;in Amsterdam in January and hope to publish a more robust version in a journal later that year.</li><br>
  Some results:
  <ul>
    <li>
      <p>It offers unifying perspective on information theory developing the subject as a purely mathematical theory (so no narratives about systems of messages or strings of symbols etc.). &nbsp;<br /><span>- It offers a detailed analysis of the &lsquo;flow of information&rsquo; through computational operations: starting with primitive recursion, via elementary arithmetic to polynomial functions and Diophantine equations. So via the MRDP-theorem it is really a general theory about information and computation.
    </li>
    </p>

    <p>
      The theory leads to many new insights and has interesting applications.</p>

    <li>
      <ol type="1">

        <li>
          Flow of information through more complex recursive functions like addition and multiplication is not trivial. Most striking observation: information efficiency of addition is not associative: depending on how we compute a sum of a set of numbers we loose different amounts of information during the process.&nbsp;<br 2) The theory facilitates a simple information theoretical proof of the Fueter-Polya conjecture: that states that the Cantor pairing function is the only polynomial function that maps N to NxN bijctively.&nbsp; </li>
        <li>
          This make the Cantor pairing function a universal measuring device that allows us to study infinite collections of partitions of the set natural numbers. More specifically: via the Cantor pairing function and its generalization we can split any data set into any other amount of data sets with constant costs.
        </li>
        <li>
          This allows us to measure the information in multi dimensional data sets like database tables directly without any conversion costs.
        </li>
        <li>
          On the down side it shows us that there us no hope of finding an optimal split of a data set in a model part and an ad hoc part: In any theory that contains elementary arithmetic these splits come for free. So two-part code optimization does not work for computational theories rich enough to model elementary arithmetic. This point will be addressed in depth in another paper.
        </li>
        <li>
          Using the Cantor function we can describe a polynomial time computable bijection between the set of finite sets of natural numbers and N itself.&nbsp; Thus we have an objective estimate of information in sets of numbers.
        </li>
        <li>
          Point 3) and 6) give us a tool to measure the information in dimensionless objects like large graphs directly without any conversion costs.
        </li>
        <li>
          &nbsp; Combining point 1) and 6) we prove that there is no polynomial function that orders the set of finite sets of numbers on sums: i.e. on can search systematically search for &lsquo;the n-th set of size k&rsquo; but not systematically for the &lsquo;n-th set that adds up to k&rsquo;.
        </li>

      </ol>

    </li>

    <li>
      <span><strong>Time Symmetry in Turing Machines. </strong>Just like in physics in Information theory it makes sense to study systems that live in negative time. I wrote a nice paper about this with Peter van Emde Boas. The work needs to be extended to a full overview of determnistic and non-deterministic computational architectures in positive and negative time. There appears to bee a whole <a href="/data/upload/files/papers-under-construction-/kolmogorovs-automata-english.docx">Zoo of systems with different time symmetries</a>. Here is a <a href="/data/upload/files/papers-under-construction-/taxonomy-of-turing-machines.pptx">sketch of a taxonomy</a>.&nbsp;</span>
    </li>
    <li>
      <span><strong>Meaningful Information and Creative Systems</strong>. I'm currently working on a&nbsp;</span><a title="Useful information " href="http://plato.stanford.edu/entries/information/supplement.html">computational theory of meaning</a><span>. I discovered that two-part code optimization is not a good technique for separating data in systems that contain elementary arithmatical functions (See the paper on Informartion and Computation:&nbsp;<a title="A General Theory of Information and Computation" href="https://arxiv.org/abs/1611.07829">arXiv</a>). So that part of the paper has to be rewritten. The idea is to develop a formal theory of creativity on the basis of this work and apply this to human cognition. See also my work on&nbsp;</span><a title="Schilderen voor het brein" href="http://www.schilderenvoorhetbrein.nl">painting</a><span>&nbsp;and visual information. Here is the <a href="/data/upload/files/papers-under-construction-/a-computational-theory-of-meaning.pdf">Draft paper.&nbsp;</a></span>
    </li>
    <li>
      <span><strong>Information Conservation Principle.&nbsp;</strong>Together with Amos Golan I investigated standard prefix-free Kolmogorov complexity in the context of Zellner&rsquo;s information conservation principle (ICP). We showed that prefix-free Kolmogorov complexity K is not efficient in this sense and proposed a generalized version of Kolmogorov complexity. The paper was accepted at Cie 2014 but I'm not completely happy with the result so I decided to retract it. </span><a href="/data/upload/files/papers-under-construction-/generalized-kolmogorov-complexity.pdf">Here is the draft.</a>&nbsp;In the mean time I have discovered the General Law of Conservation of Information (See the paper on Information and Computation&nbsp;<a title="A General Theory of Information and Computation" href="https://arxiv.org/abs/1611.07829">arXiv</a>). So the paper has to be rewritten.&nbsp;
    </li>
    <li>
      <span><strong>Learning by Eaxample.&nbsp;</strong>In order to solve the problems with the previous paper I developed a theory about learning by example: the meaning of an object is the complexity of the simplest &nbsp;example that identifies the object in a certain context. I was able to prove that this theory satisfies Zellners criterion under some strong conditions. I'll probably merge the two papers at some point in time. </span><a href="/data/upload/files/papers-under-construction-/informing-by-example.pdf">Here is the draft. &nbsp;</a>
    </li>
    <li>
      <strong>Storing information in a Computational Mechanism. &nbsp;</strong>An investigation into the cost of storing data in a one tape Turing machine. It turns out to be superlinear under mild assumptions. The paper was accepted at Cie 2015 but I'm still not happy with it so I decided to retract it. <a href="/data/upload/files/papers-under-construction-/chasm.pdf">Here is the paper.</a>&nbsp;It does allow me to estimate the computing power of various computational models, so in that respect it will be a building block of the theory of meaning project described above.&nbsp;
    </li>
  </ul>

  <h3>Philosophy</h3>
  <ul>

    <li>
      <span><strong>Johan Andreas dėr Mouw.</strong>&nbsp;The Dutch Poet\Philosopher Johan Andreas dėr Mouw (1863-1919) has been a life long inspiration for me. For the 2014 dėr Mouw symposium I wrote a philosphical analysis of his esthetics.&nbsp;</span><a href="/data/upload/files/papers-under-construction-/der-mouw-final.pdf">Here is the paper</a><span>(in Dutch). Inspired by dėr Mouws notion of absolute idealism I have had plans to write a monographs on the history of Solipisism for years. <a href="/data/upload/files/papers-under-construction-/notes-on-solipsis-english.pdf">Here are some notes.&nbsp;</a></span>
    </li>

  </ul>

  <h3><span style="font-size: 1.9em;">Current Collaborative Projects</span></h3>

  <p>
    <a title="Amsterdam Data Science" href="http://amsterdamdatascience.nl">AAA Data Science,</a>&nbsp; Using information theory and complex network theory to understand the structure of very large knowledge graphs, with Frank van Harmelen.&nbsp;
  </p>

  <h3>Recent Collaborative Projects</h3>

  <ul>

    <li>
      Complexity Measures for e-Science (Wp1, Wp2, <a href="http://www.data2semantics.org/">Data2Semantics</a>, P23, Commit) FInished in 2015.&nbsp;
    </li>
    <li>
      Atlas of Complexity Project (Supported by the <a href="http://www.templeton.org/">Templeton Foundation</a>) Finished 2014.
    </li>

  </ul>

</article>